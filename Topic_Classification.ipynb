{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e319006a-7b29-4518-b5da-2f3d0ee3a5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1008c8a-bb96-4de0-bcfd-d926e8f480a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = r\"C:\\Users\\Nhat Tan\\Downloads\\Train_Full\\Train_Full\"\n",
    "test_path = r\"C:\\Users\\Nhat Tan\\Downloads\\Test_Full\\Test_Full\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "904d6491-e904-440c-b650-0c0c9ee75186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_stopwords(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        stopwords = [line.strip().lower() for line in file]\n",
    "        return stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85000caa-b514-42f5-a276-2f8eafa98102",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_path = r\"C:\\Users\\Nhat Tan\\Downloads\\vietnamese-stopwords.txt\"\n",
    "stopwords_list = read_stopwords(stopwords_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c70d5230-46a5-42bb-bbc9-bc9686fdad7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from underthesea import word_tokenize\n",
    "\n",
    "def load_data(directory):\n",
    "    data = []\n",
    "    labels = [] \n",
    "    topics = os.listdir(directory)\n",
    "    for topic in topics:\n",
    "        topic_path = os.path.join(directory, topic)\n",
    "        if os.path.isdir(topic_path): \n",
    "            for filename in os.listdir(topic_path):\n",
    "                if filename.endswith(\".txt\"):\n",
    "                    filepath = os.path.join(topic_path, filename)\n",
    "                    with open(filepath, 'r', encoding='utf-16') as file:\n",
    "                        text = file.read()\n",
    "                        text = text.lower()\n",
    "                        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "                        tokens = word_tokenize(text, format=\"text\")\n",
    "                        tokens = [word for word in tokens.split() if word not in stopwords_list]\n",
    "\n",
    "                        text = \" \".join(tokens)\n",
    "                        data.append(text)\n",
    "                        labels.append(topic)\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05e19f79-4140-494d-b1cb-949cf1d2b2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels = load_data(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "363ab223-1ae6-4611-9759-f41e40130ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thành_lập dự_án policy phòng_chống hivaids vn nlđ quỹ hỗ_trợ khẩn_cấp aids hoa_kỳ thành_lập dự_án policy vn cam_kết hỗ_trợ chính_phủ nhân_dân vn đối_phó hivaidsdự_án nhiệm_vụ cải_thiện công_tác phòng_chống hivaids thông_qua lĩnh_vực xây_dựng chính_sách rà_soát văn_bản pháp_luật xây_dựng chiến_lược quảng_bá xây_dựng chương_trình đào_tạo phòng_chống hivaids kế_hoạch bố_trí nguồn_lực huấn_luyện nghiên_cứu phương_tiện truyền_thông đại_chúng tổ_chức hoạt_động kỳ_thị phân_biệt đối_xử đối_với hivaids ttxvn dự_án policy đặc_biệt quan_tâm công_tác truyền_thông phòng_chống hivaids coi biện_pháp tích_cực hữu_hiệu phòng_chống hiệu_quả hivaids thời_gian dự_án policy tiếp_tục tổ_chức hoạt_động nâng nhận_thức trách_nhiệm công_tác chỉ_đạo phòng_chống hivaids',\n",
       " '16000 vịnh nha_trang trực_ban bộ_đội biên_phòng cảng du_lịch cầu đá vĩnh_nguyên lễ vừa_qua 16000 tham_quan vịnh nha_trang 734 du_khách nước_ngoài đông 304 vịnh nha_trang đón 7019 du_khách địa_chỉ vịnh nha_trang thu_hút số_lượng du_khách tham_quan nghỉ_ngơi vui_chơi đảo hòn tằm hòn mun']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b03bffed-a770-4b03-a7b8-f78d27af16ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "sentences = [text.split() for text in train_data]\n",
    "word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "word2vec_model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f21bc35-6963-43e0-9e5a-5841c5165cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec<vocab=251719, vector_size=100, alpha=0.025>\n"
     ]
    }
   ],
   "source": [
    "print(word2vec_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2885ee60-d700-4076-a69f-0586fdcd2574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('xử_phạt', 0.8153647184371948),\n",
       " ('chấp_hành', 0.7613055109977722),\n",
       " ('chế_tài', 0.7612482309341431),\n",
       " ('quy_định', 0.7295352816581726),\n",
       " ('tái_phạm', 0.7239127159118652),\n",
       " ('hành_chính', 0.7046078443527222),\n",
       " ('nghiêm', 0.7013803720474243),\n",
       " ('nghiêm_cấm', 0.6990323066711426),\n",
       " ('nội_quy', 0.6943936944007874),\n",
       " ('quy_chế', 0.6791990995407104)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = word2vec_model.wv['vi_phạm']  # get numpy vector of a word\n",
    "sims = word2vec_model.wv.most_similar('vi_phạm', topn=10)\n",
    "sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c42e774-cd0b-415e-a6ec-a68c3a49f4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data, test_labels = load_data(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54afaa04-357e-401c-8801-9462c8b940bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mạo_hiểm rừng đa_mi hành_quân khám_phá thác sương_mù ẩn cánh rừng đa_mi hàm_thuận bắc bình_thuận bạt_ngàn hồ thủy điện đa_mi đẹp nàng công_chúa thác sương_mù hùng_vĩ ngất_uốn_lượn rồng_bạc khổng_lồ xuyên rừng thác sương_mù trời chiều chúng_tôi hồ thủy điện đa_mi rộng 625 ha hòn đảo đẹp tranh thủy_mạc dần hiện ánh hoàng_hôn huyền_ảo lưu_trú đêm đầu_tiên chúng_tôi khách_sạn ngàn sân_bay dã_chiến nhà_máy thủy_điện tất_cả dịch_vụ lo thủy_điện hạ_trại điện đêm bốn bề tối đen mực lửa bùng bất_ngờ hoài nhưỡng bí_thư chi_đoàn xã đa_mi thanh_niên xã 20 km đường đèo thăm đầu_tiên đoàn thành_phố đêm bọn rủ đi liền lời_ca_tiếng hát vang tiếng đàn guitar chập_chùng đêm rừng ấm lẫn chủ tầng 1 thác sương_mù trời tờ_mờ tiếng chim hót véo_von gọi thức_giấc đi tắm hồ chuẩn_bị sức_khỏe hành_trình xuyên rừng chạy khởi_động đôi chân hành_lý gọn_nhẹ thông_báo chuẩn_bị khám_phá thác sương_mù hành_quân xuyên rừng thác 5 km đường_mòn thử sức đôi chân ngó vực sâu hun_hút toán hướng_dẫn băng đường lối chân thác 100 m dây chuyên_dụng tay_vịn lưng_chừng thác thác hùng_vĩ thác sương_mù nét hai tầng thon thả đổ khe núi hẹp cao_ngất rồng_bạc khổng_lồ ước_chừng 100 m đường đi mùa mưa hơi_nước tung bụi mù thác gọi lãng_mạn thác mưa bay_lạc rừng 13 g lối đi chân_thác an_toàn đoàn_định bỏ_cuộc hoàng_quang_vinh tham_gia khảo_sát thiết_kế xây_dựng nhà_máy thủy điện đa_mi thác quyết_tâm đi chân_thác đường chân_thác đường ngắn nguy_hiểm gấp ánh đường địa_phương đoàn chia_tay đông đi lối cũ lối mòn đi lá khô phủ chúng_tôi tuột triền núi học bài_học đi rừng đầu_tiên vinh tươi_bám khô rơi vực toi_mạng đấy dòng suối chia thành hai nhánh vinh đi hướng khôi đường đi hướng đi đoạn giỏ đựng dây đeo suối gọi to tiếng đáp âm_thanh vang_vọng chúng_tôi bắt_đầu hoảng_tiếng thác đổ ầm_ầm lắm đi tiếp chân_thác đường trở khôi bảo phó_mặc số_phận sợ lạc 30000 ha rừng đa_mi mênh_mông chúng_tôi thống_nhất xuôi dòng trở ngã chỗ suối thấp_thoáng bóng đi đào dúi chuẩn_bị chân bờ bóng áo đỏ ánh xuất_hiện hai đứa thở_phào mặt méo_xẹo đoạn đường đi chân_thác hiểm_trở chúng_tôi tầng thác nguy_hiểm thảy_thác 120 m vinh 15 g trời tối_sầm mưa rừng trút trùm túi máy_ảnh sổ_sách bao nilông đi mưa 17 g45 lấm_lem bùn_đất xuất_hiện xe_ôm trở hẹn', 'tàu du_lịch cao_tốc thơ phnom_penh công_ty vận_tải thủy thơ hoạt_động tàu du_lịch cao_tốc hiện_đại_ảnh phục_vụ hành_khách tuyến thơ phnom_penh campuchia tàu kết_cấu vỏ thép hệ_thống máy_lạnh trang_trí nội_thất sang_trọng tốc_độ 25 hải_lýgiờ kinh_phí đầu_tư 10 tỉ đồng kế_hoạch tàu khởi_hành bến tàu thơ tp long xuyên an_giang cửa_khẩu vĩnh_xương cửa_khẩu kaomsamnor sông mekong cảng phnom_penh thời_gian hành_trình tàu bảy hai ngàychuyến giá vé 45 usd lượt đi 35 usd lượt']\n"
     ]
    }
   ],
   "source": [
    "print(test_data[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0d74e71-9637-4869-9ce1-8c60c4dc6b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_vector(text, model):\n",
    "    # Tokenize the text (ensure that your text is tokenized already)\n",
    "    tokens = text.split()\n",
    "    \n",
    "    # Initialize a list to store the word vectors\n",
    "    word_vectors = []\n",
    "    \n",
    "    for word in tokens:\n",
    "        if word in model.wv:  # Check if word exists in the Word2Vec vocabulary\n",
    "            word_vectors.append(model.wv[word])\n",
    "    \n",
    "    # If there are valid word vectors, return their average, otherwise return zeros\n",
    "    if len(word_vectors) > 0:\n",
    "        return np.mean(word_vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2b24053-72aa-4d9c-8378-4b58ed28d3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "vector_size = 100\n",
    "\n",
    "# Vectorize train and test data\n",
    "X_train = np.array([text_to_vector(text, word2vec_model) for text in train_data])\n",
    "X_test = np.array([text_to_vector(text, word2vec_model) for text in test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b040799-d7c3-4945-b5b5-5de80290b5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train_labels)\n",
    "y_test = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1adaa69a-6b71-4039-90ee-3b171e439876",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c1c6810-5287-4357-8516-e5664d845f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.2631034   0.42681104 -0.05936543  0.6502154   1.5135636   0.02773987\n",
      "   1.6333667   0.8016361   0.6094308   0.52670956 -0.31807047 -0.05158868\n",
      "   0.07444967 -0.14723514  0.25994346 -1.089825    0.33868372 -1.2496867\n",
      "   0.10198549 -0.56799126  0.28142288  0.10288019 -0.14726385  0.12671436\n",
      "  -0.4844395  -0.602833   -0.58769244 -1.863195   -0.5812434   0.36238593\n",
      "   0.60639846 -0.38305143 -0.48639616 -0.3122501   0.20691638  0.5860157\n",
      "  -1.5436785   0.2650565   0.19334495 -0.42768988 -0.07176334  0.25877407\n",
      "  -0.10819094 -0.8552596   1.4797612  -0.66410786 -0.854403   -0.45330542\n",
      "  -0.49956486  0.13480034 -0.25636047  0.35741636  1.23071     0.7874002\n",
      "   0.50709975 -0.59995055 -1.1149788  -0.02450802 -1.5195967  -0.48704642\n",
      "   0.80567396  0.32381162  0.5210639  -1.5269195  -1.4085809  -0.48561797\n",
      "   0.72158647 -0.3038811  -0.5273573  -0.70733947  0.08684669 -0.02610252\n",
      "  -0.03391518 -0.21233332 -0.15124255 -0.37510225 -0.12549481  0.00438308\n",
      "  -0.29981154  0.5537305   0.5940088   0.03565655 -0.7594653  -0.1301605\n",
      "   0.06577046 -0.2801338  -0.94644934  1.1786255   0.7909604  -0.50476\n",
      "  -1.1377883   0.69965935  0.44722494 -0.29952586  0.2150041   0.4918975\n",
      "  -0.9204091  -0.41292796  0.8740451  -0.94203764]\n",
      " [-0.22938016  0.44094312  0.11024224  0.5151995  -0.09932305 -0.17684937\n",
      "   0.73950535  0.06194144 -0.7889111   0.53780717 -0.5878035  -0.8865758\n",
      "   0.36205256 -0.12078308  0.19250423 -0.9583128   0.47909495 -1.550917\n",
      "   0.3105336  -1.0123163   0.26379365  0.20585217  0.02331843  0.03803376\n",
      "  -0.21821511 -0.4435423  -0.24013354 -0.04962424 -0.98414576  0.14524826\n",
      "   0.8711841  -0.3828955   0.23318623 -0.32252857 -0.8478813  -0.32360706\n",
      "  -1.0397471  -0.32425588 -0.44931957  0.29469606  0.3733167   0.46249098\n",
      "  -0.62481046  0.66974354  1.5973555  -0.05592989 -0.43458763 -0.83982736\n",
      "   0.35525927 -0.34178782  0.832114   -0.06781852  0.0626684  -1.0307885\n",
      "  -0.67694616  0.36989254 -0.60478616 -0.32807672 -0.23004246 -0.22837377\n",
      "  -0.6583927   0.9851021   0.8544982   0.10713832 -0.5288561   0.88567215\n",
      "  -0.279932   -0.2223776  -0.45920599  0.99046206  0.12837422  0.5031875\n",
      "  -0.7500951  -1.0462003   0.45554268  0.06908102 -0.5886899   0.9221973\n",
      "  -1.0508447   0.05393708 -0.41123977  0.412612    0.05496231  0.08304024\n",
      "   0.30007017  0.43338197 -0.31772915  0.6336993   1.2710912  -0.35695472\n",
      "  -0.24276985  0.48044842 -0.0339617  -0.27249742  0.37377915  0.34019983\n",
      "   0.228261   -0.90668285 -0.27756956 -1.1776242 ]]\n",
      "[0 0]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[:2])\n",
    "print(y_train[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e5e18ca8-bb63-41ad-ac23-ae8fc8320c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33759, 100)\n",
      "(33759,)\n"
     ]
    }
   ],
   "source": [
    "X_train_combined = np.concatenate((X_train, X_val), axis=0)\n",
    "y_train_combined = np.concatenate((y_train, y_val), axis=0)\n",
    "\n",
    "print(X_train_combined.shape)\n",
    "print(y_train_combined.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "defa3e07-b728-452d-b7ca-31cf583cdc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "def Report(y_test, y_pred):\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "34f54dd7-8002-4e0f-9811-17722457845e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_combined)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "df725360-376e-4ff3-a3e5-940b2559fdea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.20713012  0.6892172  -0.04107564 -0.22420135  0.6910475  -0.4502266\n",
      "   0.20160027  0.5894731   0.2698518   0.02230131 -0.30387297 -0.46725643\n",
      "   0.21648869  0.18691823  0.5731317  -0.08401296  0.5783362  -0.23982118\n",
      "   0.34852862 -0.76917875 -0.45552522  0.3750897  -0.22753935  0.6453554\n",
      "  -0.34341934  0.1725434  -0.34902897 -0.18481028 -0.10661989  0.132446\n",
      "   0.63435525 -0.25165302  0.6192655  -0.31550348 -0.26817256  0.4385681\n",
      "  -0.32351488 -0.28222266 -0.17526044 -0.09072046 -0.10484883  0.46490052\n",
      "   0.37714607  0.40674     0.44938275 -0.06794545 -0.17081742  0.5382455\n",
      "  -0.46342427  0.42512164  0.6207291   0.29231444  0.05373027 -0.02141318\n",
      "   0.39828336 -0.20859756 -0.24312052  0.31296563 -0.1998789  -0.00367341\n",
      "   0.04063943  0.5368873   0.09381363  0.41265804 -0.8136403   0.647963\n",
      "  -0.16768578 -0.769532   -0.07618523  0.2487806  -0.647232   -0.07670046\n",
      "   0.12940708 -0.98855734 -0.7496544   0.4267364   0.07831406  0.5990688\n",
      "  -0.6073192   0.43093142  0.00465997  0.11229101  0.28464594 -0.08994511\n",
      "  -0.06323997  0.6079469  -0.42437914  0.6495656   0.64337313 -0.486331\n",
      "  -0.54378706 -0.23504049  0.0157063  -0.53699505  0.8781899   0.17108484\n",
      "  -0.34941527 -0.7647021   0.38234812 -0.8408816 ]\n",
      " [-0.15864913  0.4388679   0.01183551  0.5161731   0.9426647  -0.10278599\n",
      "   0.7771201   0.2772712   0.01863532  0.354248   -0.44493157 -0.6841907\n",
      "   0.83229375 -0.08291062  0.2154939  -1.054343    0.55491024 -0.7070539\n",
      "  -0.4273545  -0.52277523  0.40905032  0.10384227 -0.41770428  0.28116822\n",
      "  -0.8957819  -0.20151994 -0.8568056  -0.71253824 -0.5044547   0.08645058\n",
      "   0.7820832  -0.08626203 -0.10466298 -0.9488627  -0.3726766   0.13346301\n",
      "  -0.45422462 -0.4227648  -0.88491666  0.01578463  0.23869911  0.4015023\n",
      "   0.16273743 -0.19933349  0.8877287  -0.12874739  0.10776044 -0.29099494\n",
      "  -0.12183762  0.03739421  0.19045015 -0.13758525 -0.02531927 -0.9825671\n",
      "   0.26625407 -0.22194213 -0.34405783  0.50086284 -0.37444425 -0.6604451\n",
      "   0.663907    0.09007667  0.650979   -0.12109377 -1.0069015   0.23955372\n",
      "   0.57765406 -0.26613995 -1.2397122   0.62017107  0.02193927  0.34012872\n",
      "   0.40325838 -1.1868601  -0.2096354   0.02589139  0.14252266  0.18828897\n",
      "  -0.4942622   0.30315125 -0.28728896 -0.63014525 -0.564998    0.2584963\n",
      "  -0.06747819 -0.85152274  0.2484537   0.59758276  1.4058796  -0.11757038\n",
      "   0.08312841  0.13460606  0.27353117  0.55539954 -0.7535854   0.24869336\n",
      "  -0.17273775 -0.29482028  0.22458075 -0.8494109 ]]\n",
      "[8 4]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[:2])\n",
    "print(y_train[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f5bef707-d588-40c9-be09-244cbf078a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "NB_model = GaussianNB()\n",
    "NB_model.fit(X_train_scaled, y_train_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b6624530-6d8d-4399-8aa3-47ab688468d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7911579616064162\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.72      0.72      7567\n",
      "           1       0.44      0.64      0.52      2036\n",
      "           2       0.59      0.63      0.61      2096\n",
      "           3       0.74      0.84      0.79      5276\n",
      "           4       0.79      0.86      0.82      3788\n",
      "           5       0.92      0.77      0.84      5417\n",
      "           6       0.85      0.81      0.83      6716\n",
      "           7       0.98      0.84      0.90      6667\n",
      "           8       0.80      0.85      0.82      6250\n",
      "           9       0.85      0.79      0.82      4560\n",
      "\n",
      "    accuracy                           0.79     50373\n",
      "   macro avg       0.77      0.77      0.77     50373\n",
      "weighted avg       0.81      0.79      0.80     50373\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = NB_model.predict(X_test_scaled)\n",
    "Report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e2b39c40-bf38-4100-8b68-45a934084971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1dacd449-0c61-4a9d-a82c-481c6faa7d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import SimpleRNN, Dense, Embedding\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3524dd06-f956-46a6-bc92-1ee4660db38e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = tf.config.list_physical_devices('GPU')[0]  \n",
    "tf.config.set_visible_devices(device, 'GPU')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6e3ba4d6-f0ca-432b-a5ee-5a6a515483b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.wv.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "664de11b-536a-47e2-a280-a2e60f836694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33759 100\n",
      "(33759,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_scaled.shape[0],X_train_scaled.shape[1])\n",
    "print(y_train_combined.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6a5d990c-838c-4213-87df-fa8239cb18cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_model = Sequential([\n",
    "    SimpleRNN(512, return_sequences=False, input_shape=(1,100)),\n",
    "    Dense(512, activation='relu'),\n",
    "    # Dense Layer cho phân loại nhiều lớp\n",
    "    Dense(len(set(y_train_combined)), activation='softmax')  \n",
    "])\n",
    "\n",
    "RNN_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4df508f7-60f6-4790-96dc-896b37ee5eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_8 (SimpleRNN)     (None, 512)               313856    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 581,642\n",
      "Trainable params: 581,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "RNN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7b6ae8b2-fbb3-4cc8-a28a-15c617adc83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7406a21d-a84d-46c1-b51b-83b288941d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1055/1055 [==============================] - 6s 4ms/step - loss: 0.4511 - accuracy: 0.8481\n",
      "Epoch 2/5\n",
      "1055/1055 [==============================] - 5s 4ms/step - loss: 0.3711 - accuracy: 0.8717\n",
      "Epoch 3/5\n",
      "1055/1055 [==============================] - 4s 4ms/step - loss: 0.3362 - accuracy: 0.8822\n",
      "Epoch 4/5\n",
      "1055/1055 [==============================] - 5s 5ms/step - loss: 0.3101 - accuracy: 0.8911\n",
      "Epoch 5/5\n",
      "1055/1055 [==============================] - 5s 5ms/step - loss: 0.2858 - accuracy: 0.8992\n"
     ]
    }
   ],
   "source": [
    "history = RNN_model.fit(X_train_reshaped, y_train_combined, epochs=5, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3d41701d-c2a1-4979-8cfd-6600674e5daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], 1, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "14509c33-5909-4d9b-94c5-f8bbbdc0b327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50373, 1, 100)\n"
     ]
    }
   ],
   "source": [
    "print(X_test_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bf6a5827-de8a-4fb6-b136-708b727f4ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8728684017231453\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83      7567\n",
      "           1       0.74      0.45      0.56      2036\n",
      "           2       0.70      0.78      0.74      2096\n",
      "           3       0.87      0.86      0.87      5276\n",
      "           4       0.80      0.93      0.86      3788\n",
      "           5       0.93      0.87      0.90      5417\n",
      "           6       0.90      0.90      0.90      6716\n",
      "           7       0.93      0.98      0.95      6667\n",
      "           8       0.91      0.90      0.91      6250\n",
      "           9       0.93      0.88      0.90      4560\n",
      "\n",
      "    accuracy                           0.87     50373\n",
      "   macro avg       0.85      0.84      0.84     50373\n",
      "weighted avg       0.87      0.87      0.87     50373\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = RNN_model.predict(X_test_reshaped)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "Report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5efac6ef-a127-4c5b-a30b-9f19856906ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5b2b3d0b-059b-4786-971d-cf2f03e4e198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_8 (LSTM)                (None, 1, 256)            365568    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 1, 256)            0         \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 128)               197120    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 567,146\n",
      "Trainable params: 567,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "LSTM_model = Sequential([\n",
    "    LSTM(256, input_shape=(1,100), activation='relu', return_sequences=True), \n",
    "    Dropout(0.2),\n",
    "    LSTM(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(len(set(y_train_combined)), activation='softmax')  \n",
    "])\n",
    "\n",
    "LSTM_model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(LSTM_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ee556848-4915-4b57-a47f-ced69233e54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train_categorized = to_categorical(y_train_combined, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3f4150ee-e2e6-45d0-991b-6cc631694349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1055/1055 [==============================] - 18s 11ms/step - loss: 0.6697 - accuracy: 0.8017\n",
      "Epoch 2/5\n",
      "1055/1055 [==============================] - 14s 13ms/step - loss: 0.4722 - accuracy: 0.8544\n",
      "Epoch 3/5\n",
      "1055/1055 [==============================] - 12s 12ms/step - loss: 0.4212 - accuracy: 0.8676\n",
      "Epoch 4/5\n",
      "1055/1055 [==============================] - 13s 12ms/step - loss: 0.3908 - accuracy: 0.8754\n",
      "Epoch 5/5\n",
      "1055/1055 [==============================] - 13s 12ms/step - loss: 0.3630 - accuracy: 0.8821\n"
     ]
    }
   ],
   "source": [
    "history = LSTM_model.fit(X_train_reshaped, y_train_categorized, epochs=5, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "be5b8cf8-306b-4b84-b95c-6158a7c283c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8871220693625553\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.84      7567\n",
      "           1       0.73      0.58      0.65      2036\n",
      "           2       0.72      0.79      0.75      2096\n",
      "           3       0.92      0.81      0.87      5276\n",
      "           4       0.84      0.94      0.89      3788\n",
      "           5       0.93      0.90      0.91      5417\n",
      "           6       0.93      0.91      0.92      6716\n",
      "           7       0.97      0.97      0.97      6667\n",
      "           8       0.90      0.92      0.91      6250\n",
      "           9       0.89      0.93      0.91      4560\n",
      "\n",
      "    accuracy                           0.89     50373\n",
      "   macro avg       0.87      0.86      0.86     50373\n",
      "weighted avg       0.89      0.89      0.89     50373\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = LSTM_model.predict(X_test_reshaped)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "Report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4723fb4e-958c-4e81-88e3-16994aa1b1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import GRU\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "21faf29d-5593-4420-bd69-45f07a49acc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_14 (GRU)                 (None, 1, 256)            274944    \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 1, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_15 (GRU)                 (None, 128)               148224    \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 427,626\n",
      "Trainable params: 427,626\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "GRU_model = Sequential([\n",
    "    GRU(units=256, return_sequences=True, input_shape=(1,100), activation='tanh'),\n",
    "    Dropout(0.2),\n",
    "    GRU(units=128, activation='tanh'),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(len(set(y_train_combined)), activation='softmax')  \n",
    "])\n",
    "GRU_model.compile(optimizer=SGD(lr=0.01, decay=1e-7, momentum=0.9, nesterov=False),loss='mean_squared_error')\n",
    "print(GRU_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3b8b3e2c-b29b-4fbf-96c2-6fd7f8ad4862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1055/1055 [==============================] - 13s 7ms/step - loss: 0.0858\n",
      "Epoch 2/5\n",
      "1055/1055 [==============================] - 7s 6ms/step - loss: 0.0657\n",
      "Epoch 3/5\n",
      "1055/1055 [==============================] - 7s 6ms/step - loss: 0.0478\n",
      "Epoch 4/5\n",
      "1055/1055 [==============================] - 8s 8ms/step - loss: 0.0387\n",
      "Epoch 5/5\n",
      "1055/1055 [==============================] - 8s 7ms/step - loss: 0.0341\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fc5c7ed400>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GRU_model.fit(X_train_reshaped, y_train_categorized, epochs=5, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "70a387bb-12a8-44fa-9c10-bb035344b68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.817560994977468\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.81      0.77      7567\n",
      "           1       0.49      0.66      0.56      2036\n",
      "           2       0.82      0.35      0.49      2096\n",
      "           3       0.83      0.76      0.79      5276\n",
      "           4       0.81      0.89      0.85      3788\n",
      "           5       0.86      0.87      0.86      5417\n",
      "           6       0.87      0.86      0.86      6716\n",
      "           7       0.94      0.93      0.93      6667\n",
      "           8       0.84      0.82      0.83      6250\n",
      "           9       0.82      0.84      0.83      4560\n",
      "\n",
      "    accuracy                           0.82     50373\n",
      "   macro avg       0.80      0.78      0.78     50373\n",
      "weighted avg       0.82      0.82      0.82     50373\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = GRU_model.predict(X_test_reshaped)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "Report(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
